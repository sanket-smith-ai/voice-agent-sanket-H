# ğŸ™ï¸ AI Voice Agent â€“ Low-Latency, Open-Source Demo

This repository contains a **real-time AI voice agent** built to demonstrate **low-latency AI system design**, practical engineering trade-offs, and clean architecture using **open-source models only**.

The application enables **voice-to-voice interaction**:

> Speak â†’ Transcribe â†’ Generate AI response â†’ Convert to speech â†’ Play audio

The primary goal of this project is **technical evaluation**, not production scale.

---

## âœ¨ Key Highlights

* âš¡ **Low-latency focused architecture**
* ğŸ¤ Microphone-based voice input
* ğŸ“ Fast speech-to-text using Whisper (small model)
* ğŸ§  Lightweight local LLM for response generation
* ğŸ”Š Text-to-speech output
* ğŸ–¥ï¸ Streamlit UI for easy testing and demonstration
* ğŸ“¦ Automatic model download on first run

---

## ğŸ—ï¸ High-Level Architecture

```
Microphone
   â†“
Voice Activity Detection (VAD)
   â†“
Speech-to-Text (Whisper)
   â†“
LLM Response Generation
   â†“
Sentence Chunking
   â†“
Text-to-Speech
   â†“
Speaker Output
```

Each component is modular and can be replaced independently.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                 # Streamlit frontend (recommended)
â”œâ”€â”€ main.py                # CLI-based voice agent
â”œâ”€â”€ llm_engine.py          # LLM inference logic
â”œâ”€â”€ whisper_stt.py         # Speech-to-text logic
â”œâ”€â”€ model_manager.py       # Auto-download & model setup
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Setup & usage guide
â”œâ”€â”€ README_NOTES.md        # Architecture decisions & trade-offs
â”œâ”€â”€ .gitignore             # Excludes models, env, cache
â”œâ”€â”€ vad.py             # Voice activity detection
â”œâ”€â”€ tts.py             # Text-to-speech
â””â”€â”€ chunker.py         # Sentence chunking for smooth TTS
```

> ğŸ“ **Model files, virtual environments, and cache directories are intentionally excluded from Git.**

---

## ğŸ’» System Requirements

* **Python 3.10 (recommended)**
* Working microphone
* Internet connection (first run only â€“ for model download)
* OS: Windows / macOS / Linux

---

## ğŸš€ Quick Start (Easy Setup)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/sanket-smith-ai/voice-agent-sanket-H.git
cd Simuphish
```

---

### 2ï¸âƒ£ Create & Activate Virtual Environment

**Windows**

```bash
python -m venv aivoice
aivoice\Scripts\activate
```

**macOS / Linux**

```bash
python3 -m venv aivoice
source aivoice/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

â³ **Note:**
On the **first run**, required models (STT, LLM, TTS) will be downloaded automatically.

---

## â–¶ï¸ Running the Voice Agent (Recommended)

### âœ… Streamlit UI (Best for Testing)

```bash
streamlit run app.py
```

* A browser window opens automatically
* Click **ğŸ¤ Speak**
* Speak naturally into your microphone
* The UI shows:

  * â€œListeningâ€¦â€ while recording
  * Transcribed user speech
  * AI response text
* The AI responds **with voice output**

âœ” This is the **recommended way to evaluate the voice agent**.

---

## ğŸ§ª CLI Mode (Optional)

For terminal-only testing:

```bash
python main.py
```

* Records a short audio clip
* Transcribes speech
* Generates AI response
* Plays TTS output
* Useful for quick latency checks

---

## ğŸ¯ Design Intent

This project is intentionally designed to be:

* **Easy to run**
* **Easy to understand**
* **Easy to extend**

All components run **locally** using open-source models to avoid external API dependencies.

---

## âš ï¸ Limitations & Assumptions

* Uses **small open-source models** for faster local inference
* Responses may be less detailed than large proprietary models
* Single-user, demo-focused setup
* Not optimized for high background noise
* English-only (current configuration)

---

## ğŸ”® Future Improvements

* Streaming STT and token-level LLM output
* WebSocket-based real-time audio pipeline
* Cloud LLM / TTS integration
* Multi-language support
* Long-term conversational memory

---

## ğŸ“„ Additional Notes

For detailed explanations on:

* Architecture decisions
* Latency optimizations
* Trade-offs and constraints

ğŸ‘‰ See **README_NOTES.md**

---

## ğŸ“Œ Summary

This project demonstrates:

* Real-time AI system design
* Latency-aware engineering choices
* Clean modular architecture
* Practical use of open-source AI models


---



